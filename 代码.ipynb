{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导包\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential#该模型可以构建非常复杂的神经网络\n",
    "from keras.layers import Dense#Dense为定义网络层的基本方法\n",
    "from sklearn.model_selection import train_test_split#train_test_split用来随机划分训练集和测试集\n",
    "import matplotlib.pyplot as plt#其为python上一个二维绘图库\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #设置字体\n",
    "plt.rcParams['axes.unicode_minus']=False #字符显示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Administrator/Desktop/mortality.csv\")#读取文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()#将df的值赋值给df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#归一化：将数据缩放到（0,1）范围内\n",
    "df1.loc[:,'year'] = (df1.loc[:,'year']-1995)/(2017-1995)\n",
    "df1.loc[:,'age'] = (df1.loc[:,'age']-0)/(100-0)\n",
    "df1.loc[:,'region'] = (df1.loc[:,'region']-1)/(4-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分为训练集和测试集\n",
    "train_X,test_X,train_y,test_y = train_test_split(df1.iloc[:,0:4],df1.iloc[:,4],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          year   age  gender    region\n",
       " 2444  0.590909  0.05       0  1.000000\n",
       " 3170  0.818182  0.05       1  0.000000\n",
       " 3878  1.000000  0.25       1  0.000000\n",
       " 2291  0.590909  0.10       1  0.000000\n",
       " 3121  0.772727  0.90       0  0.333333\n",
       " ...        ...   ...     ...       ...\n",
       " 2941  0.727273  0.70       0  0.333333\n",
       " 3177  0.818182  0.40       1  0.000000\n",
       " 3489  0.863636  0.60       0  0.666667\n",
       " 638   0.136364  0.00       0  0.333333\n",
       " 2818  0.727273  0.05       1  0.000000\n",
       " \n",
       " [3238 rows x 4 columns],           year   age  gender    region\n",
       " 2479  0.636364  0.70       1  0.000000\n",
       " 1495  0.363636  1.00       1  1.000000\n",
       " 3733  0.954545  0.70       1  0.333333\n",
       " 172   0.000000  0.85       0  1.000000\n",
       " 192   0.045455  0.75       1  0.000000\n",
       " ...        ...   ...     ...       ...\n",
       " 1591  0.409091  0.30       1  0.000000\n",
       " 3098  0.772727  0.85       0  0.000000\n",
       " 1824  0.454545  0.95       1  0.666667\n",
       " 1665  0.409091  0.70       1  1.000000\n",
       " 825   0.181818  0.50       0  0.333333\n",
       " \n",
       " [810 rows x 4 columns], 2444   -8.222660\n",
       " 3170   -8.145630\n",
       " 3878   -7.469874\n",
       " 2291   -7.347346\n",
       " 3121   -1.813273\n",
       "           ...   \n",
       " 2941   -4.257334\n",
       " 3177   -6.023988\n",
       " 3489   -4.777145\n",
       " 638    -4.285989\n",
       " 2818   -7.561682\n",
       " Name: y, Length: 3238, dtype: float64, 2479   -3.474091\n",
       " 1495   -0.581581\n",
       " 3733   -4.016828\n",
       " 172    -1.822370\n",
       " 192    -2.464747\n",
       "           ...   \n",
       " 1591   -6.444021\n",
       " 3098   -2.141471\n",
       " 1824   -1.130653\n",
       " 1665   -3.038014\n",
       " 825    -6.281817\n",
       " Name: y, Length: 810, dtype: float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X,test_X,train_y,test_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\ana\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\ana\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3238 samples, validate on 810 samples\n",
      "Epoch 1/1000\n",
      "3238/3238 [==============================] - 0s 44us/step - loss: 20.9291 - val_loss: 12.2170\n",
      "Epoch 2/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 9.6889 - val_loss: 7.7464\n",
      "Epoch 3/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 6.6740 - val_loss: 5.2387\n",
      "Epoch 4/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 4.2204 - val_loss: 3.1905\n",
      "Epoch 5/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 2.5338 - val_loss: 2.3688\n",
      "Epoch 6/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 1.8514 - val_loss: 1.8048\n",
      "Epoch 7/1000\n",
      "3238/3238 [==============================] - 0s 16us/step - loss: 1.5404 - val_loss: 1.4726\n",
      "Epoch 8/1000\n",
      "3238/3238 [==============================] - 0s 16us/step - loss: 1.3349 - val_loss: 1.3504\n",
      "Epoch 9/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 1.1861 - val_loss: 1.1379\n",
      "Epoch 10/1000\n",
      "3238/3238 [==============================] - 0s 16us/step - loss: 1.0698 - val_loss: 1.0220\n",
      "Epoch 11/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.9851 - val_loss: 1.1577\n",
      "Epoch 12/1000\n",
      "3238/3238 [==============================] - 0s 17us/step - loss: 0.9089 - val_loss: 0.8648\n",
      "Epoch 13/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.8503 - val_loss: 0.9528\n",
      "Epoch 14/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.8216 - val_loss: 0.7840\n",
      "Epoch 15/1000\n",
      "3238/3238 [==============================] - 0s 16us/step - loss: 0.7857 - val_loss: 0.7443\n",
      "Epoch 16/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.7302 - val_loss: 0.7732\n",
      "Epoch 17/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.7066 - val_loss: 0.6836\n",
      "Epoch 18/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.6846 - val_loss: 0.6482\n",
      "Epoch 19/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.6421 - val_loss: 0.6352\n",
      "Epoch 20/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.6380 - val_loss: 0.6097\n",
      "Epoch 21/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.6290 - val_loss: 0.5913\n",
      "Epoch 22/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.5926 - val_loss: 0.5921\n",
      "Epoch 23/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.5796 - val_loss: 0.6100\n",
      "Epoch 24/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.5866 - val_loss: 0.5441\n",
      "Epoch 25/1000\n",
      "3238/3238 [==============================] - 0s 16us/step - loss: 0.5608 - val_loss: 0.6612\n",
      "Epoch 26/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.5569 - val_loss: 0.5132\n",
      "Epoch 27/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.5420 - val_loss: 0.5254\n",
      "Epoch 28/1000\n",
      "3238/3238 [==============================] - 0s 16us/step - loss: 0.5329 - val_loss: 0.5567\n",
      "Epoch 29/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.5181 - val_loss: 0.5635\n",
      "Epoch 30/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.5183 - val_loss: 0.4730\n",
      "Epoch 31/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.5189 - val_loss: 0.4975\n",
      "Epoch 32/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.4827 - val_loss: 0.6511\n",
      "Epoch 33/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.4934 - val_loss: 0.4597\n",
      "Epoch 34/1000\n",
      "3238/3238 [==============================] - 0s 18us/step - loss: 0.4860 - val_loss: 0.4390\n",
      "Epoch 35/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.4691 - val_loss: 0.4582\n",
      "Epoch 36/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.4685 - val_loss: 0.5202\n",
      "Epoch 37/1000\n",
      "3238/3238 [==============================] - 0s 18us/step - loss: 0.4605 - val_loss: 0.5081\n",
      "Epoch 38/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.4506 - val_loss: 0.4881\n",
      "Epoch 39/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.4429 - val_loss: 0.5988\n",
      "Epoch 40/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.4391 - val_loss: 0.4736\n",
      "Epoch 41/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.4298 - val_loss: 0.4446\n",
      "Epoch 42/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.4287 - val_loss: 0.4574\n",
      "Epoch 43/1000\n",
      "3238/3238 [==============================] - 0s 16us/step - loss: 0.4139 - val_loss: 0.3969\n",
      "Epoch 44/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.4150 - val_loss: 0.3655\n",
      "Epoch 45/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.4120 - val_loss: 0.4053\n",
      "Epoch 46/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.3901 - val_loss: 0.4784\n",
      "Epoch 47/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.3931 - val_loss: 0.3809\n",
      "Epoch 48/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.3942 - val_loss: 0.4756\n",
      "Epoch 49/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.3817 - val_loss: 0.3459\n",
      "Epoch 50/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.3884 - val_loss: 0.3713\n",
      "Epoch 51/1000\n",
      "3238/3238 [==============================] - 0s 28us/step - loss: 0.3732 - val_loss: 0.3464\n",
      "Epoch 52/1000\n",
      "3238/3238 [==============================] - 0s 24us/step - loss: 0.3647 - val_loss: 0.3501\n",
      "Epoch 53/1000\n",
      "3238/3238 [==============================] - 0s 23us/step - loss: 0.3627 - val_loss: 0.3233\n",
      "Epoch 54/1000\n",
      "3238/3238 [==============================] - 0s 17us/step - loss: 0.3585 - val_loss: 0.3499\n",
      "Epoch 55/1000\n",
      "3238/3238 [==============================] - 0s 19us/step - loss: 0.3488 - val_loss: 0.3700\n",
      "Epoch 56/1000\n",
      "3238/3238 [==============================] - 0s 25us/step - loss: 0.3478 - val_loss: 0.3730\n",
      "Epoch 57/1000\n",
      "3238/3238 [==============================] - 0s 19us/step - loss: 0.3412 - val_loss: 0.4029\n",
      "Epoch 58/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.3438 - val_loss: 0.3259\n",
      "Epoch 59/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.3335 - val_loss: 0.3366\n",
      "Epoch 60/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.3256 - val_loss: 0.4008\n",
      "Epoch 61/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.3313 - val_loss: 0.3142\n",
      "Epoch 62/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.3251 - val_loss: 0.2831\n",
      "Epoch 63/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.3219 - val_loss: 0.2935\n",
      "Epoch 64/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.3106 - val_loss: 0.3192\n",
      "Epoch 65/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.3151 - val_loss: 0.2826\n",
      "Epoch 66/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.3098 - val_loss: 0.2822\n",
      "Epoch 67/1000\n",
      "3238/3238 [==============================] - 0s 16us/step - loss: 0.2966 - val_loss: 0.2697\n",
      "Epoch 68/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.2981 - val_loss: 0.2949\n",
      "Epoch 69/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.2989 - val_loss: 0.3374\n",
      "Epoch 70/1000\n",
      "3238/3238 [==============================] - 0s 16us/step - loss: 0.2890 - val_loss: 0.2607\n",
      "Epoch 71/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.2882 - val_loss: 0.2549\n",
      "Epoch 72/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.2892 - val_loss: 0.2562\n",
      "Epoch 73/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.2832 - val_loss: 0.3249\n",
      "Epoch 74/1000\n",
      "3238/3238 [==============================] - 0s 18us/step - loss: 0.2877 - val_loss: 0.2511\n",
      "Epoch 75/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.2809 - val_loss: 0.2812\n",
      "Epoch 76/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2793 - val_loss: 0.2670\n",
      "Epoch 77/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2768 - val_loss: 0.2354\n",
      "Epoch 78/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2687 - val_loss: 0.2904\n",
      "Epoch 79/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.2701 - val_loss: 0.2656\n",
      "Epoch 80/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.2793 - val_loss: 0.3437\n",
      "Epoch 81/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2601 - val_loss: 0.2410\n",
      "Epoch 82/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2741 - val_loss: 0.3163\n",
      "Epoch 83/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.2612 - val_loss: 0.3201\n",
      "Epoch 84/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2573 - val_loss: 0.4146\n",
      "Epoch 85/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.2735 - val_loss: 0.2654\n",
      "Epoch 86/1000\n",
      "3238/3238 [==============================] - 0s 25us/step - loss: 0.2589 - val_loss: 0.2636\n",
      "Epoch 87/1000\n",
      "3238/3238 [==============================] - 0s 29us/step - loss: 0.2547 - val_loss: 0.2929\n",
      "Epoch 88/1000\n",
      "3238/3238 [==============================] - 0s 27us/step - loss: 0.2555 - val_loss: 0.2610\n",
      "Epoch 89/1000\n",
      "3238/3238 [==============================] - 0s 27us/step - loss: 0.2508 - val_loss: 0.3401\n",
      "Epoch 90/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2602 - val_loss: 0.2392\n",
      "Epoch 91/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2466 - val_loss: 0.3053\n",
      "Epoch 92/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2564 - val_loss: 0.2354\n",
      "Epoch 93/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.2512 - val_loss: 0.2684\n",
      "Epoch 94/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.2548 - val_loss: 0.2911\n",
      "Epoch 95/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2517 - val_loss: 0.2372\n",
      "Epoch 96/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2556 - val_loss: 0.2317\n",
      "Epoch 97/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.2478 - val_loss: 0.2691\n",
      "Epoch 98/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2407 - val_loss: 0.2886\n",
      "Epoch 99/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2600 - val_loss: 0.2253\n",
      "Epoch 100/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2488 - val_loss: 0.2094\n",
      "Epoch 101/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.2382 - val_loss: 0.2218\n",
      "Epoch 102/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.2571 - val_loss: 0.2215\n",
      "Epoch 103/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2441 - val_loss: 0.2038\n",
      "Epoch 104/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.2425 - val_loss: 0.2623\n",
      "Epoch 105/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2344 - val_loss: 0.2882\n",
      "Epoch 106/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2467 - val_loss: 0.2691\n",
      "Epoch 107/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2392 - val_loss: 0.2443\n",
      "Epoch 108/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2387 - val_loss: 0.2231\n",
      "Epoch 109/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.2416 - val_loss: 0.2103\n",
      "Epoch 110/1000\n",
      "3238/3238 [==============================] - 0s 17us/step - loss: 0.2313 - val_loss: 0.2678\n",
      "Epoch 111/1000\n",
      "3238/3238 [==============================] - 0s 27us/step - loss: 0.2368 - val_loss: 0.2478\n",
      "Epoch 112/1000\n",
      "3238/3238 [==============================] - 0s 28us/step - loss: 0.2336 - val_loss: 0.2187\n",
      "Epoch 113/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.2247 - val_loss: 0.2311\n",
      "Epoch 114/1000\n",
      "3238/3238 [==============================] - 0s 18us/step - loss: 0.2327 - val_loss: 0.1971\n",
      "Epoch 115/1000\n",
      "3238/3238 [==============================] - 0s 24us/step - loss: 0.2351 - val_loss: 0.2668\n",
      "Epoch 116/1000\n",
      "3238/3238 [==============================] - 0s 32us/step - loss: 0.2322 - val_loss: 0.2482\n",
      "Epoch 117/1000\n",
      "3238/3238 [==============================] - 0s 25us/step - loss: 0.2225 - val_loss: 0.1906\n",
      "Epoch 118/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2318 - val_loss: 0.1996\n",
      "Epoch 119/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2308 - val_loss: 0.1907\n",
      "Epoch 120/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2228 - val_loss: 0.1860\n",
      "Epoch 121/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2235 - val_loss: 0.2092\n",
      "Epoch 122/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2266 - val_loss: 0.1862\n",
      "Epoch 123/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.2150 - val_loss: 0.1886\n",
      "Epoch 124/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2261 - val_loss: 0.1852\n",
      "Epoch 125/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.2169 - val_loss: 0.2701\n",
      "Epoch 126/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2397 - val_loss: 0.2017\n",
      "Epoch 127/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.2074 - val_loss: 0.2174\n",
      "Epoch 128/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2260 - val_loss: 0.2024\n",
      "Epoch 129/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.2083 - val_loss: 0.2125\n",
      "Epoch 130/1000\n",
      "3238/3238 [==============================] - 0s 20us/step - loss: 0.2151 - val_loss: 0.2257\n",
      "Epoch 131/1000\n",
      "3238/3238 [==============================] - 0s 26us/step - loss: 0.2067 - val_loss: 0.3107\n",
      "Epoch 132/1000\n",
      "3238/3238 [==============================] - 0s 23us/step - loss: 0.2146 - val_loss: 0.2780\n",
      "Epoch 133/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.2233 - val_loss: 0.2202\n",
      "Epoch 134/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2100 - val_loss: 0.1733\n",
      "Epoch 135/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2060 - val_loss: 0.1710\n",
      "Epoch 136/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2059 - val_loss: 0.2669\n",
      "Epoch 137/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.2069 - val_loss: 0.1871\n",
      "Epoch 138/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.2119 - val_loss: 0.1838\n",
      "Epoch 139/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.2056 - val_loss: 0.2196\n",
      "Epoch 140/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2013 - val_loss: 0.2152\n",
      "Epoch 141/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2101 - val_loss: 0.1936\n",
      "Epoch 142/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.2008 - val_loss: 0.2413\n",
      "Epoch 143/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1916 - val_loss: 0.2583\n",
      "Epoch 144/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.2066 - val_loss: 0.2012\n",
      "Epoch 145/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1944 - val_loss: 0.2127\n",
      "Epoch 146/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1956 - val_loss: 0.1555\n",
      "Epoch 147/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.2008 - val_loss: 0.1963\n",
      "Epoch 148/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.1884 - val_loss: 0.2027\n",
      "Epoch 149/1000\n",
      "3238/3238 [==============================] - 0s 23us/step - loss: 0.2012 - val_loss: 0.2167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/1000\n",
      "3238/3238 [==============================] - 0s 29us/step - loss: 0.1945 - val_loss: 0.1744\n",
      "Epoch 151/1000\n",
      "3238/3238 [==============================] - 0s 16us/step - loss: 0.2041 - val_loss: 0.1574\n",
      "Epoch 152/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1846 - val_loss: 0.1463\n",
      "Epoch 153/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1910 - val_loss: 0.2292\n",
      "Epoch 154/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1916 - val_loss: 0.1649\n",
      "Epoch 155/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1889 - val_loss: 0.2315\n",
      "Epoch 156/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1794 - val_loss: 0.2360\n",
      "Epoch 157/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1881 - val_loss: 0.1493\n",
      "Epoch 158/1000\n",
      "3238/3238 [==============================] - 0s 23us/step - loss: 0.1838 - val_loss: 0.2183\n",
      "Epoch 159/1000\n",
      "3238/3238 [==============================] - 0s 29us/step - loss: 0.1832 - val_loss: 0.1455\n",
      "Epoch 160/1000\n",
      "3238/3238 [==============================] - 0s 19us/step - loss: 0.1818 - val_loss: 0.2283\n",
      "Epoch 161/1000\n",
      "3238/3238 [==============================] - 0s 19us/step - loss: 0.1782 - val_loss: 0.2311\n",
      "Epoch 162/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.1802 - val_loss: 0.1384\n",
      "Epoch 163/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1761 - val_loss: 0.1429\n",
      "Epoch 164/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1855 - val_loss: 0.1981\n",
      "Epoch 165/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1791 - val_loss: 0.1580\n",
      "Epoch 166/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1818 - val_loss: 0.1593\n",
      "Epoch 167/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1742 - val_loss: 0.1531\n",
      "Epoch 168/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1662 - val_loss: 0.1322\n",
      "Epoch 169/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1737 - val_loss: 0.2007\n",
      "Epoch 170/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1754 - val_loss: 0.2842\n",
      "Epoch 171/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.1707 - val_loss: 0.1472\n",
      "Epoch 172/1000\n",
      "3238/3238 [==============================] - 0s 21us/step - loss: 0.1766 - val_loss: 0.2334\n",
      "Epoch 173/1000\n",
      "3238/3238 [==============================] - 0s 26us/step - loss: 0.1778 - val_loss: 0.1692\n",
      "Epoch 174/1000\n",
      "3238/3238 [==============================] - 0s 25us/step - loss: 0.1709 - val_loss: 0.1270\n",
      "Epoch 175/1000\n",
      "3238/3238 [==============================] - ETA: 0s - loss: 0.173 - 0s 24us/step - loss: 0.1698 - val_loss: 0.1593\n",
      "Epoch 176/1000\n",
      "3238/3238 [==============================] - 0s 26us/step - loss: 0.1698 - val_loss: 0.1302\n",
      "Epoch 177/1000\n",
      "3238/3238 [==============================] - 0s 32us/step - loss: 0.1630 - val_loss: 0.1407\n",
      "Epoch 178/1000\n",
      "3238/3238 [==============================] - 0s 27us/step - loss: 0.1750 - val_loss: 0.1225\n",
      "Epoch 179/1000\n",
      "3238/3238 [==============================] - 0s 34us/step - loss: 0.1675 - val_loss: 0.1383\n",
      "Epoch 180/1000\n",
      "3238/3238 [==============================] - 0s 33us/step - loss: 0.1635 - val_loss: 0.2201\n",
      "Epoch 181/1000\n",
      "3238/3238 [==============================] - 0s 33us/step - loss: 0.1640 - val_loss: 0.1366\n",
      "Epoch 182/1000\n",
      "3238/3238 [==============================] - 0s 31us/step - loss: 0.1665 - val_loss: 0.1805\n",
      "Epoch 183/1000\n",
      "3238/3238 [==============================] - 0s 21us/step - loss: 0.1655 - val_loss: 0.2315\n",
      "Epoch 184/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.1586 - val_loss: 0.2366\n",
      "Epoch 185/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1671 - val_loss: 0.1647\n",
      "Epoch 186/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1578 - val_loss: 0.1206\n",
      "Epoch 187/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1644 - val_loss: 0.1829\n",
      "Epoch 188/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1576 - val_loss: 0.1143\n",
      "Epoch 189/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1559 - val_loss: 0.2255\n",
      "Epoch 190/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1626 - val_loss: 0.1693\n",
      "Epoch 191/1000\n",
      "3238/3238 [==============================] - 0s 20us/step - loss: 0.1497 - val_loss: 0.1889\n",
      "Epoch 192/1000\n",
      "3238/3238 [==============================] - 0s 27us/step - loss: 0.1746 - val_loss: 0.1284\n",
      "Epoch 193/1000\n",
      "3238/3238 [==============================] - 0s 28us/step - loss: 0.1554 - val_loss: 0.1090\n",
      "Epoch 194/1000\n",
      "3238/3238 [==============================] - 0s 23us/step - loss: 0.1571 - val_loss: 0.1860\n",
      "Epoch 195/1000\n",
      "3238/3238 [==============================] - 0s 37us/step - loss: 0.1704 - val_loss: 0.1716\n",
      "Epoch 196/1000\n",
      "3238/3238 [==============================] - 0s 49us/step - loss: 0.1518 - val_loss: 0.1736\n",
      "Epoch 197/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.1571 - val_loss: 0.1661\n",
      "Epoch 198/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1599 - val_loss: 0.1782\n",
      "Epoch 199/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1605 - val_loss: 0.1242\n",
      "Epoch 200/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1505 - val_loss: 0.1992\n",
      "Epoch 201/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.1609 - val_loss: 0.1300\n",
      "Epoch 202/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.1504 - val_loss: 0.1709\n",
      "Epoch 203/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.1527 - val_loss: 0.1762\n",
      "Epoch 204/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1614 - val_loss: 0.1522\n",
      "Epoch 205/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1586 - val_loss: 0.1173\n",
      "Epoch 206/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1531 - val_loss: 0.1064\n",
      "Epoch 207/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1545 - val_loss: 0.1478\n",
      "Epoch 208/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1546 - val_loss: 0.1458\n",
      "Epoch 209/1000\n",
      "3238/3238 [==============================] - 0s 18us/step - loss: 0.1609 - val_loss: 0.1289\n",
      "Epoch 210/1000\n",
      "3238/3238 [==============================] - 0s 18us/step - loss: 0.1477 - val_loss: 0.1069\n",
      "Epoch 211/1000\n",
      "3238/3238 [==============================] - 0s 19us/step - loss: 0.1460 - val_loss: 0.1659\n",
      "Epoch 212/1000\n",
      "3238/3238 [==============================] - 0s 19us/step - loss: 0.1657 - val_loss: 0.1001\n",
      "Epoch 213/1000\n",
      "3238/3238 [==============================] - 0s 18us/step - loss: 0.1524 - val_loss: 0.1114\n",
      "Epoch 214/1000\n",
      "3238/3238 [==============================] - 0s 18us/step - loss: 0.1518 - val_loss: 0.1313\n",
      "Epoch 215/1000\n",
      "3238/3238 [==============================] - 0s 21us/step - loss: 0.1578 - val_loss: 0.1016\n",
      "Epoch 216/1000\n",
      "3238/3238 [==============================] - 0s 20us/step - loss: 0.1541 - val_loss: 0.1269\n",
      "Epoch 217/1000\n",
      "3238/3238 [==============================] - 0s 19us/step - loss: 0.1453 - val_loss: 0.1408\n",
      "Epoch 218/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1554 - val_loss: 0.1221\n",
      "Epoch 219/1000\n",
      "3238/3238 [==============================] - 0s 18us/step - loss: 0.1489 - val_loss: 0.1282\n",
      "Epoch 220/1000\n",
      "3238/3238 [==============================] - 0s 18us/step - loss: 0.1550 - val_loss: 0.1257\n",
      "Epoch 221/1000\n",
      "3238/3238 [==============================] - 0s 22us/step - loss: 0.1446 - val_loss: 0.1889\n",
      "Epoch 222/1000\n",
      "3238/3238 [==============================] - 0s 20us/step - loss: 0.1508 - val_loss: 0.1692\n",
      "Epoch 223/1000\n",
      "3238/3238 [==============================] - 0s 19us/step - loss: 0.1513 - val_loss: 0.1324\n",
      "Epoch 224/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.1500 - val_loss: 0.1702\n",
      "Epoch 225/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.1524 - val_loss: 0.1543\n",
      "Epoch 226/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - ETA: 0s - loss: 0.145 - 0s 21us/step - loss: 0.1465 - val_loss: 0.1158\n",
      "Epoch 227/1000\n",
      "3238/3238 [==============================] - 0s 25us/step - loss: 0.1538 - val_loss: 0.1705\n",
      "Epoch 228/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.1477 - val_loss: 0.2135\n",
      "Epoch 229/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1532 - val_loss: 0.1079\n",
      "Epoch 230/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1543 - val_loss: 0.1286\n",
      "Epoch 231/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1479 - val_loss: 0.1605\n",
      "Epoch 232/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1461 - val_loss: 0.1058\n",
      "Epoch 233/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1542 - val_loss: 0.1012\n",
      "Epoch 234/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1421 - val_loss: 0.1792\n",
      "Epoch 235/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1455 - val_loss: 0.1203\n",
      "Epoch 236/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.1522 - val_loss: 0.1378\n",
      "Epoch 237/1000\n",
      "3238/3238 [==============================] - 0s 18us/step - loss: 0.1482 - val_loss: 0.2002\n",
      "Epoch 238/1000\n",
      "3238/3238 [==============================] - 0s 17us/step - loss: 0.1424 - val_loss: 0.1463\n",
      "Epoch 239/1000\n",
      "3238/3238 [==============================] - 0s 16us/step - loss: 0.1539 - val_loss: 0.1846\n",
      "Epoch 240/1000\n",
      "3238/3238 [==============================] - 0s 17us/step - loss: 0.1507 - val_loss: 0.1359\n",
      "Epoch 241/1000\n",
      "3238/3238 [==============================] - 0s 18us/step - loss: 0.1496 - val_loss: 0.1118\n",
      "Epoch 242/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1370 - val_loss: 0.1003\n",
      "Epoch 243/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1567 - val_loss: 0.1263\n",
      "Epoch 244/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1429 - val_loss: 0.1025\n",
      "Epoch 245/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1458 - val_loss: 0.1724\n",
      "Epoch 246/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1507 - val_loss: 0.1021\n",
      "Epoch 247/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1465 - val_loss: 0.1216\n",
      "Epoch 248/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1427 - val_loss: 0.2337\n",
      "Epoch 249/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1439 - val_loss: 0.1355\n",
      "Epoch 250/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1422 - val_loss: 0.1026\n",
      "Epoch 251/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1485 - val_loss: 0.1544\n",
      "Epoch 252/1000\n",
      "3238/3238 [==============================] - 0s 16us/step - loss: 0.1473 - val_loss: 0.1665\n",
      "Epoch 253/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.1416 - val_loss: 0.2233\n",
      "Epoch 254/1000\n",
      "3238/3238 [==============================] - 0s 18us/step - loss: 0.1483 - val_loss: 0.0962\n",
      "Epoch 255/1000\n",
      "3238/3238 [==============================] - 0s 18us/step - loss: 0.1466 - val_loss: 0.0995\n",
      "Epoch 256/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.1486 - val_loss: 0.2094\n",
      "Epoch 257/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1512 - val_loss: 0.1629\n",
      "Epoch 258/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1512 - val_loss: 0.1470\n",
      "Epoch 259/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1316 - val_loss: 0.0972\n",
      "Epoch 260/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1511 - val_loss: 0.1352\n",
      "Epoch 261/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1393 - val_loss: 0.2075\n",
      "Epoch 262/1000\n",
      "3238/3238 [==============================] - 0s 22us/step - loss: 0.1452 - val_loss: 0.0969\n",
      "Epoch 263/1000\n",
      "3238/3238 [==============================] - 0s 23us/step - loss: 0.1477 - val_loss: 0.1558\n",
      "Epoch 264/1000\n",
      "3238/3238 [==============================] - 0s 23us/step - loss: 0.1449 - val_loss: 0.2191\n",
      "Epoch 265/1000\n",
      "3238/3238 [==============================] - 0s 17us/step - loss: 0.1474 - val_loss: 0.1216\n",
      "Epoch 266/1000\n",
      "3238/3238 [==============================] - 0s 18us/step - loss: 0.1395 - val_loss: 0.2383\n",
      "Epoch 267/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1490 - val_loss: 0.1457\n",
      "Epoch 268/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1382 - val_loss: 0.2001\n",
      "Epoch 269/1000\n",
      "3238/3238 [==============================] - 0s 23us/step - loss: 0.1494 - val_loss: 0.1620\n",
      "Epoch 270/1000\n",
      "3238/3238 [==============================] - 0s 29us/step - loss: 0.1489 - val_loss: 0.1543\n",
      "Epoch 271/1000\n",
      "3238/3238 [==============================] - 0s 28us/step - loss: 0.1401 - val_loss: 0.1283\n",
      "Epoch 272/1000\n",
      "3238/3238 [==============================] - 0s 25us/step - loss: 0.1499 - val_loss: 0.1313\n",
      "Epoch 273/1000\n",
      "3238/3238 [==============================] - 0s 29us/step - loss: 0.1383 - val_loss: 0.1205\n",
      "Epoch 274/1000\n",
      "3238/3238 [==============================] - 0s 16us/step - loss: 0.1489 - val_loss: 0.1074\n",
      "Epoch 275/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1401 - val_loss: 0.1096\n",
      "Epoch 276/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1465 - val_loss: 0.1217\n",
      "Epoch 277/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1393 - val_loss: 0.1693\n",
      "Epoch 278/1000\n",
      "3238/3238 [==============================] - 0s 9us/step - loss: 0.1395 - val_loss: 0.1447\n",
      "Epoch 279/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1444 - val_loss: 0.1008\n",
      "Epoch 280/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1431 - val_loss: 0.1088\n",
      "Epoch 281/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.1457 - val_loss: 0.1131\n",
      "Epoch 282/1000\n",
      "3238/3238 [==============================] - 0s 21us/step - loss: 0.1413 - val_loss: 0.1615\n",
      "Epoch 283/1000\n",
      "3238/3238 [==============================] - 0s 21us/step - loss: 0.1454 - val_loss: 0.1068\n",
      "Epoch 284/1000\n",
      "3238/3238 [==============================] - 0s 23us/step - loss: 0.1451 - val_loss: 0.0962\n",
      "Epoch 285/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1463 - val_loss: 0.1406\n",
      "Epoch 286/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1397 - val_loss: 0.1365\n",
      "Epoch 287/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1414 - val_loss: 0.1248\n",
      "Epoch 288/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1476 - val_loss: 0.1586\n",
      "Epoch 289/1000\n",
      "3238/3238 [==============================] - 0s 19us/step - loss: 0.1429 - val_loss: 0.1611\n",
      "Epoch 290/1000\n",
      "3238/3238 [==============================] - 0s 25us/step - loss: 0.1378 - val_loss: 0.1856\n",
      "Epoch 291/1000\n",
      "3238/3238 [==============================] - 0s 29us/step - loss: 0.1467 - val_loss: 0.1275\n",
      "Epoch 292/1000\n",
      "3238/3238 [==============================] - 0s 16us/step - loss: 0.1382 - val_loss: 0.1144\n",
      "Epoch 293/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1411 - val_loss: 0.1353\n",
      "Epoch 294/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1427 - val_loss: 0.1228\n",
      "Epoch 295/1000\n",
      "3238/3238 [==============================] - 0s 26us/step - loss: 0.1412 - val_loss: 0.1482\n",
      "Epoch 296/1000\n",
      "3238/3238 [==============================] - 0s 31us/step - loss: 0.1505 - val_loss: 0.1372\n",
      "Epoch 297/1000\n",
      "3238/3238 [==============================] - 0s 27us/step - loss: 0.1358 - val_loss: 0.1043\n",
      "Epoch 298/1000\n",
      "3238/3238 [==============================] - 0s 22us/step - loss: 0.1329 - val_loss: 0.1398\n",
      "Epoch 299/1000\n",
      "3238/3238 [==============================] - 0s 26us/step - loss: 0.1484 - val_loss: 0.1604\n",
      "Epoch 300/1000\n",
      "3238/3238 [==============================] - 0s 29us/step - loss: 0.1337 - val_loss: 0.2880\n",
      "Epoch 301/1000\n",
      "3238/3238 [==============================] - 0s 25us/step - loss: 0.1485 - val_loss: 0.1146\n",
      "Epoch 302/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1371 - val_loss: 0.1952\n",
      "Epoch 303/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1391 - val_loss: 0.1228\n",
      "Epoch 304/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1469 - val_loss: 0.1299\n",
      "Epoch 305/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1452 - val_loss: 0.1236\n",
      "Epoch 306/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1390 - val_loss: 0.1248\n",
      "Epoch 307/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1405 - val_loss: 0.0978\n",
      "Epoch 308/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1396 - val_loss: 0.1257\n",
      "Epoch 309/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1439 - val_loss: 0.1227\n",
      "Epoch 310/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1390 - val_loss: 0.1794\n",
      "Epoch 311/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1428 - val_loss: 0.1136\n",
      "Epoch 312/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1443 - val_loss: 0.1261\n",
      "Epoch 313/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1347 - val_loss: 0.2581\n",
      "Epoch 314/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1496 - val_loss: 0.0982\n",
      "Epoch 315/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1354 - val_loss: 0.1594\n",
      "Epoch 316/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1410 - val_loss: 0.1514\n",
      "Epoch 317/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1322 - val_loss: 0.0997\n",
      "Epoch 318/1000\n",
      "3238/3238 [==============================] - 0s 9us/step - loss: 0.1473 - val_loss: 0.1548\n",
      "Epoch 319/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1429 - val_loss: 0.1013\n",
      "Epoch 320/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1349 - val_loss: 0.1621\n",
      "Epoch 321/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1491 - val_loss: 0.1418\n",
      "Epoch 322/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1327 - val_loss: 0.1303\n",
      "Epoch 323/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1436 - val_loss: 0.1733\n",
      "Epoch 324/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1350 - val_loss: 0.1678\n",
      "Epoch 325/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1389 - val_loss: 0.1204\n",
      "Epoch 326/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1444 - val_loss: 0.0944\n",
      "Epoch 327/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1369 - val_loss: 0.2060\n",
      "Epoch 328/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1396 - val_loss: 0.1792\n",
      "Epoch 329/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1411 - val_loss: 0.1055\n",
      "Epoch 330/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1480 - val_loss: 0.0998\n",
      "Epoch 331/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1353 - val_loss: 0.1293\n",
      "Epoch 332/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1454 - val_loss: 0.0966\n",
      "Epoch 333/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1381 - val_loss: 0.1312\n",
      "Epoch 334/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1418 - val_loss: 0.1329\n",
      "Epoch 335/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1358 - val_loss: 0.1927\n",
      "Epoch 336/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1377 - val_loss: 0.1542\n",
      "Epoch 337/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1429 - val_loss: 0.1334\n",
      "Epoch 338/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1404 - val_loss: 0.1164\n",
      "Epoch 339/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1448 - val_loss: 0.1314\n",
      "Epoch 340/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.1375 - val_loss: 0.1515\n",
      "Epoch 341/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1403 - val_loss: 0.1134\n",
      "Epoch 342/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1301 - val_loss: 0.1247\n",
      "Epoch 343/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1454 - val_loss: 0.1456\n",
      "Epoch 344/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1382 - val_loss: 0.1515\n",
      "Epoch 345/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1313 - val_loss: 0.1670\n",
      "Epoch 346/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1352 - val_loss: 0.1770\n",
      "Epoch 347/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.1395 - val_loss: 0.1806\n",
      "Epoch 348/1000\n",
      "3238/3238 [==============================] - ETA: 0s - loss: 0.169 - 0s 13us/step - loss: 0.1410 - val_loss: 0.1510\n",
      "Epoch 349/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1399 - val_loss: 0.0979\n",
      "Epoch 350/1000\n",
      "3238/3238 [==============================] - 0s 19us/step - loss: 0.1400 - val_loss: 0.1453\n",
      "Epoch 351/1000\n",
      "3238/3238 [==============================] - 0s 17us/step - loss: 0.1418 - val_loss: 0.1692\n",
      "Epoch 352/1000\n",
      "3238/3238 [==============================] - 0s 23us/step - loss: 0.1377 - val_loss: 0.1453\n",
      "Epoch 353/1000\n",
      "3238/3238 [==============================] - 0s 23us/step - loss: 0.1404 - val_loss: 0.0999\n",
      "Epoch 354/1000\n",
      "3238/3238 [==============================] - 0s 34us/step - loss: 0.1410 - val_loss: 0.1550\n",
      "Epoch 355/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1392 - val_loss: 0.0996\n",
      "Epoch 356/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.1360 - val_loss: 0.2230\n",
      "Epoch 357/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.1323 - val_loss: 0.1656\n",
      "Epoch 358/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.1410 - val_loss: 0.1140\n",
      "Epoch 359/1000\n",
      "3238/3238 [==============================] - 0s 31us/step - loss: 0.1355 - val_loss: 0.1176\n",
      "Epoch 360/1000\n",
      "3238/3238 [==============================] - 0s 33us/step - loss: 0.1458 - val_loss: 0.1109\n",
      "Epoch 361/1000\n",
      "3238/3238 [==============================] - 0s 39us/step - loss: 0.1290 - val_loss: 0.1135\n",
      "Epoch 362/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1433 - val_loss: 0.1510\n",
      "Epoch 363/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1388 - val_loss: 0.1027\n",
      "Epoch 364/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1407 - val_loss: 0.1203\n",
      "Epoch 365/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1349 - val_loss: 0.1271\n",
      "Epoch 366/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1423 - val_loss: 0.1008\n",
      "Epoch 367/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1361 - val_loss: 0.1004\n",
      "Epoch 368/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1395 - val_loss: 0.1205\n",
      "Epoch 369/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1312 - val_loss: 0.1124\n",
      "Epoch 370/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1362 - val_loss: 0.2360\n",
      "Epoch 371/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1362 - val_loss: 0.1012\n",
      "Epoch 372/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1440 - val_loss: 0.0937\n",
      "Epoch 373/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1344 - val_loss: 0.1999\n",
      "Epoch 374/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1345 - val_loss: 0.1138\n",
      "Epoch 375/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1384 - val_loss: 0.1603\n",
      "Epoch 376/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1391 - val_loss: 0.1229\n",
      "Epoch 377/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1341 - val_loss: 0.1173\n",
      "Epoch 378/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1441 - val_loss: 0.1079\n",
      "Epoch 379/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1355 - val_loss: 0.1725\n",
      "Epoch 380/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1361 - val_loss: 0.1124\n",
      "Epoch 381/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1334 - val_loss: 0.1914\n",
      "Epoch 382/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1360 - val_loss: 0.1223\n",
      "Epoch 383/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1353 - val_loss: 0.1272\n",
      "Epoch 384/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1250 - val_loss: 0.2657\n",
      "Epoch 385/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1429 - val_loss: 0.0986\n",
      "Epoch 386/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1409 - val_loss: 0.1315\n",
      "Epoch 387/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1400 - val_loss: 0.0930\n",
      "Epoch 388/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1304 - val_loss: 0.0959\n",
      "Epoch 389/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1386 - val_loss: 0.1053\n",
      "Epoch 390/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1342 - val_loss: 0.1102\n",
      "Epoch 391/1000\n",
      "3238/3238 [==============================] - 0s 9us/step - loss: 0.1374 - val_loss: 0.1485\n",
      "Epoch 392/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1390 - val_loss: 0.1144\n",
      "Epoch 393/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1379 - val_loss: 0.1240\n",
      "Epoch 394/1000\n",
      "3238/3238 [==============================] - ETA: 0s - loss: 0.132 - 0s 25us/step - loss: 0.1360 - val_loss: 0.1199\n",
      "Epoch 395/1000\n",
      "3238/3238 [==============================] - 0s 17us/step - loss: 0.1352 - val_loss: 0.1247\n",
      "Epoch 396/1000\n",
      "3238/3238 [==============================] - 0s 26us/step - loss: 0.1430 - val_loss: 0.1046\n",
      "Epoch 397/1000\n",
      "3238/3238 [==============================] - 0s 27us/step - loss: 0.1311 - val_loss: 0.1278\n",
      "Epoch 398/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1382 - val_loss: 0.1189\n",
      "Epoch 399/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1360 - val_loss: 0.0994\n",
      "Epoch 400/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1304 - val_loss: 0.0989\n",
      "Epoch 401/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1414 - val_loss: 0.1232\n",
      "Epoch 402/1000\n",
      "3238/3238 [==============================] - 0s 19us/step - loss: 0.1351 - val_loss: 0.0995\n",
      "Epoch 403/1000\n",
      "3238/3238 [==============================] - 0s 30us/step - loss: 0.1339 - val_loss: 0.1464\n",
      "Epoch 404/1000\n",
      "3238/3238 [==============================] - 0s 34us/step - loss: 0.1347 - val_loss: 0.1027\n",
      "Epoch 405/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.1375 - val_loss: 0.1400\n",
      "Epoch 406/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1314 - val_loss: 0.1332\n",
      "Epoch 407/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1365 - val_loss: 0.0995\n",
      "Epoch 408/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1400 - val_loss: 0.1395\n",
      "Epoch 409/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1300 - val_loss: 0.1833\n",
      "Epoch 410/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1447 - val_loss: 0.1066\n",
      "Epoch 411/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1315 - val_loss: 0.1071\n",
      "Epoch 412/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1409 - val_loss: 0.1099\n",
      "Epoch 413/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1390 - val_loss: 0.1158\n",
      "Epoch 414/1000\n",
      "3238/3238 [==============================] - 0s 27us/step - loss: 0.1319 - val_loss: 0.0982\n",
      "Epoch 415/1000\n",
      "3238/3238 [==============================] - 0s 29us/step - loss: 0.1317 - val_loss: 0.1189\n",
      "Epoch 416/1000\n",
      "3238/3238 [==============================] - 0s 22us/step - loss: 0.1335 - val_loss: 0.1103\n",
      "Epoch 417/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1303 - val_loss: 0.1050\n",
      "Epoch 418/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1438 - val_loss: 0.1013\n",
      "Epoch 419/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1324 - val_loss: 0.2522\n",
      "Epoch 420/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1335 - val_loss: 0.1196\n",
      "Epoch 421/1000\n",
      "3238/3238 [==============================] - 0s 19us/step - loss: 0.1369 - val_loss: 0.1294\n",
      "Epoch 422/1000\n",
      "3238/3238 [==============================] - 0s 19us/step - loss: 0.1321 - val_loss: 0.1359\n",
      "Epoch 423/1000\n",
      "3238/3238 [==============================] - 0s 26us/step - loss: 0.1295 - val_loss: 0.1256\n",
      "Epoch 424/1000\n",
      "3238/3238 [==============================] - 0s 16us/step - loss: 0.1350 - val_loss: 0.1014\n",
      "Epoch 425/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1393 - val_loss: 0.1187\n",
      "Epoch 426/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1286 - val_loss: 0.1617\n",
      "Epoch 427/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1346 - val_loss: 0.0978\n",
      "Epoch 428/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1323 - val_loss: 0.1957\n",
      "Epoch 429/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1321 - val_loss: 0.1678\n",
      "Epoch 430/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1365 - val_loss: 0.1204\n",
      "Epoch 431/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1324 - val_loss: 0.1205\n",
      "Epoch 432/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1343 - val_loss: 0.0984\n",
      "Epoch 433/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1377 - val_loss: 0.1255\n",
      "Epoch 434/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1335 - val_loss: 0.1102\n",
      "Epoch 435/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1267 - val_loss: 0.1623\n",
      "Epoch 436/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1403 - val_loss: 0.1243\n",
      "Epoch 437/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1311 - val_loss: 0.1016\n",
      "Epoch 438/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1370 - val_loss: 0.1427\n",
      "Epoch 439/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1261 - val_loss: 0.1163\n",
      "Epoch 440/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1389 - val_loss: 0.1170\n",
      "Epoch 441/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1330 - val_loss: 0.1406\n",
      "Epoch 442/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1358 - val_loss: 0.1047\n",
      "Epoch 443/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1305 - val_loss: 0.1610\n",
      "Epoch 444/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1310 - val_loss: 0.1332\n",
      "Epoch 445/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1353 - val_loss: 0.1727\n",
      "Epoch 446/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1344 - val_loss: 0.1598\n",
      "Epoch 447/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1237 - val_loss: 0.2031\n",
      "Epoch 448/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1411 - val_loss: 0.0982\n",
      "Epoch 449/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1345 - val_loss: 0.1683\n",
      "Epoch 450/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1315 - val_loss: 0.1275\n",
      "Epoch 451/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1339 - val_loss: 0.1479\n",
      "Epoch 452/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1321 - val_loss: 0.2151\n",
      "Epoch 453/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1365 - val_loss: 0.1256\n",
      "Epoch 454/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1340 - val_loss: 0.0977\n",
      "Epoch 455/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1298 - val_loss: 0.1488\n",
      "Epoch 456/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1341 - val_loss: 0.1472\n",
      "Epoch 457/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1354 - val_loss: 0.0967\n",
      "Epoch 458/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1213 - val_loss: 0.1792\n",
      "Epoch 459/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1389 - val_loss: 0.1546\n",
      "Epoch 460/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1286 - val_loss: 0.0963\n",
      "Epoch 461/1000\n",
      "3238/3238 [==============================] - 0s 9us/step - loss: 0.1341 - val_loss: 0.1182\n",
      "Epoch 462/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1247 - val_loss: 0.1372\n",
      "Epoch 463/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1351 - val_loss: 0.1827\n",
      "Epoch 464/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1390 - val_loss: 0.1612\n",
      "Epoch 465/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1360 - val_loss: 0.0926\n",
      "Epoch 466/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1289 - val_loss: 0.1339\n",
      "Epoch 467/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1356 - val_loss: 0.0961\n",
      "Epoch 468/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1333 - val_loss: 0.1012\n",
      "Epoch 469/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1243 - val_loss: 0.1234\n",
      "Epoch 470/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1360 - val_loss: 0.1333\n",
      "Epoch 471/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1361 - val_loss: 0.1897\n",
      "Epoch 472/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1284 - val_loss: 0.1165\n",
      "Epoch 473/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1408 - val_loss: 0.1184\n",
      "Epoch 474/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1239 - val_loss: 0.1955\n",
      "Epoch 475/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1401 - val_loss: 0.1138\n",
      "Epoch 476/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1288 - val_loss: 0.0976\n",
      "Epoch 477/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1352 - val_loss: 0.1585\n",
      "Epoch 478/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1313 - val_loss: 0.1104\n",
      "Epoch 479/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1387 - val_loss: 0.1209\n",
      "Epoch 480/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1288 - val_loss: 0.0994\n",
      "Epoch 481/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1347 - val_loss: 0.1839\n",
      "Epoch 482/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1291 - val_loss: 0.1267\n",
      "Epoch 483/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1353 - val_loss: 0.1071\n",
      "Epoch 484/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1370 - val_loss: 0.1072\n",
      "Epoch 485/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1273 - val_loss: 0.2086\n",
      "Epoch 486/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1339 - val_loss: 0.1276\n",
      "Epoch 487/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1243 - val_loss: 0.2195\n",
      "Epoch 488/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1321 - val_loss: 0.1179\n",
      "Epoch 489/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1328 - val_loss: 0.0938\n",
      "Epoch 490/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1329 - val_loss: 0.1204\n",
      "Epoch 491/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1243 - val_loss: 0.0929\n",
      "Epoch 492/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1340 - val_loss: 0.1470\n",
      "Epoch 493/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1295 - val_loss: 0.0942\n",
      "Epoch 494/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1333 - val_loss: 0.1204\n",
      "Epoch 495/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1317 - val_loss: 0.1385\n",
      "Epoch 496/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1313 - val_loss: 0.1340\n",
      "Epoch 497/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1308 - val_loss: 0.1784\n",
      "Epoch 498/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1345 - val_loss: 0.1007\n",
      "Epoch 499/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1319 - val_loss: 0.1040\n",
      "Epoch 500/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1251 - val_loss: 0.1375\n",
      "Epoch 501/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1282 - val_loss: 0.1491\n",
      "Epoch 502/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1355 - val_loss: 0.1257\n",
      "Epoch 503/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1301 - val_loss: 0.1319\n",
      "Epoch 504/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1397 - val_loss: 0.1409\n",
      "Epoch 505/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1279 - val_loss: 0.1595\n",
      "Epoch 506/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1292 - val_loss: 0.1107\n",
      "Epoch 507/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1305 - val_loss: 0.0963\n",
      "Epoch 508/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1329 - val_loss: 0.1238\n",
      "Epoch 509/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1264 - val_loss: 0.1205\n",
      "Epoch 510/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1353 - val_loss: 0.1116\n",
      "Epoch 511/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1228 - val_loss: 0.1012\n",
      "Epoch 512/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1309 - val_loss: 0.1013\n",
      "Epoch 513/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1299 - val_loss: 0.1592\n",
      "Epoch 514/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1239 - val_loss: 0.1546\n",
      "Epoch 515/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1349 - val_loss: 0.1428\n",
      "Epoch 516/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1390 - val_loss: 0.1069\n",
      "Epoch 517/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1300 - val_loss: 0.1009\n",
      "Epoch 518/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1287 - val_loss: 0.1010\n",
      "Epoch 519/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1288 - val_loss: 0.1136\n",
      "Epoch 520/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1298 - val_loss: 0.1326\n",
      "Epoch 521/1000\n",
      "3238/3238 [==============================] - 0s 9us/step - loss: 0.1344 - val_loss: 0.1852\n",
      "Epoch 522/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1298 - val_loss: 0.0917\n",
      "Epoch 523/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1278 - val_loss: 0.1596\n",
      "Epoch 524/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1321 - val_loss: 0.1109\n",
      "Epoch 525/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1302 - val_loss: 0.1338\n",
      "Epoch 526/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1319 - val_loss: 0.1126\n",
      "Epoch 527/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1348 - val_loss: 0.0947\n",
      "Epoch 528/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1255 - val_loss: 0.1032\n",
      "Epoch 529/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1289 - val_loss: 0.1487\n",
      "Epoch 530/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1277 - val_loss: 0.1057\n",
      "Epoch 531/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1309 - val_loss: 0.1153\n",
      "Epoch 532/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1332 - val_loss: 0.0984\n",
      "Epoch 533/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1288 - val_loss: 0.1471\n",
      "Epoch 534/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1313 - val_loss: 0.1374\n",
      "Epoch 535/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1307 - val_loss: 0.1215\n",
      "Epoch 536/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1346 - val_loss: 0.1655\n",
      "Epoch 537/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1234 - val_loss: 0.1001\n",
      "Epoch 538/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1325 - val_loss: 0.1449\n",
      "Epoch 539/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1277 - val_loss: 0.1067\n",
      "Epoch 540/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1232 - val_loss: 0.1784\n",
      "Epoch 541/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1382 - val_loss: 0.1259\n",
      "Epoch 542/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1233 - val_loss: 0.1550\n",
      "Epoch 543/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1231 - val_loss: 0.1752\n",
      "Epoch 544/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1314 - val_loss: 0.1513\n",
      "Epoch 545/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1292 - val_loss: 0.1775\n",
      "Epoch 546/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1228 - val_loss: 0.1184\n",
      "Epoch 547/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1365 - val_loss: 0.1088\n",
      "Epoch 548/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1274 - val_loss: 0.1540\n",
      "Epoch 549/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1291 - val_loss: 0.0958\n",
      "Epoch 550/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1232 - val_loss: 0.1121\n",
      "Epoch 551/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1337 - val_loss: 0.1392\n",
      "Epoch 552/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1246 - val_loss: 0.1229\n",
      "Epoch 553/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1265 - val_loss: 0.1232\n",
      "Epoch 554/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1290 - val_loss: 0.1781\n",
      "Epoch 555/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1300 - val_loss: 0.0970\n",
      "Epoch 556/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1345 - val_loss: 0.1008\n",
      "Epoch 557/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1249 - val_loss: 0.1053\n",
      "Epoch 558/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1323 - val_loss: 0.1624\n",
      "Epoch 559/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1285 - val_loss: 0.1096\n",
      "Epoch 560/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1356 - val_loss: 0.1006\n",
      "Epoch 561/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1238 - val_loss: 0.1408\n",
      "Epoch 562/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1299 - val_loss: 0.0975\n",
      "Epoch 563/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1317 - val_loss: 0.1289\n",
      "Epoch 564/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1265 - val_loss: 0.1600\n",
      "Epoch 565/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1257 - val_loss: 0.1056\n",
      "Epoch 566/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1317 - val_loss: 0.1092\n",
      "Epoch 567/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1257 - val_loss: 0.1251\n",
      "Epoch 568/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1310 - val_loss: 0.1634\n",
      "Epoch 569/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1331 - val_loss: 0.1432\n",
      "Epoch 570/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1304 - val_loss: 0.1143\n",
      "Epoch 571/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1209 - val_loss: 0.1660\n",
      "Epoch 572/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1309 - val_loss: 0.1211\n",
      "Epoch 573/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1263 - val_loss: 0.1208\n",
      "Epoch 574/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1310 - val_loss: 0.1849\n",
      "Epoch 575/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1278 - val_loss: 0.1008\n",
      "Epoch 576/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1291 - val_loss: 0.1188\n",
      "Epoch 577/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1292 - val_loss: 0.1141\n",
      "Epoch 578/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1294 - val_loss: 0.0977\n",
      "Epoch 579/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1241 - val_loss: 0.2445\n",
      "Epoch 580/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1357 - val_loss: 0.0935\n",
      "Epoch 581/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1222 - val_loss: 0.1697\n",
      "Epoch 582/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1331 - val_loss: 0.1087\n",
      "Epoch 583/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1276 - val_loss: 0.1615\n",
      "Epoch 584/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1273 - val_loss: 0.0974\n",
      "Epoch 585/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1248 - val_loss: 0.1372\n",
      "Epoch 586/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1337 - val_loss: 0.0936\n",
      "Epoch 587/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1273 - val_loss: 0.1152\n",
      "Epoch 588/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1225 - val_loss: 0.1076\n",
      "Epoch 589/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1308 - val_loss: 0.1369\n",
      "Epoch 590/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1264 - val_loss: 0.1536\n",
      "Epoch 591/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1305 - val_loss: 0.0937\n",
      "Epoch 592/1000\n",
      "3238/3238 [==============================] - 0s 9us/step - loss: 0.1311 - val_loss: 0.1268\n",
      "Epoch 593/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1268 - val_loss: 0.1522\n",
      "Epoch 594/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1190 - val_loss: 0.1951\n",
      "Epoch 595/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1319 - val_loss: 0.1126\n",
      "Epoch 596/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1287 - val_loss: 0.1131\n",
      "Epoch 597/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1290 - val_loss: 0.1626\n",
      "Epoch 598/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1254 - val_loss: 0.1100\n",
      "Epoch 599/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1278 - val_loss: 0.1366\n",
      "Epoch 600/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1343 - val_loss: 0.1019\n",
      "Epoch 601/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1270 - val_loss: 0.0966\n",
      "Epoch 602/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1287 - val_loss: 0.1058\n",
      "Epoch 603/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1260 - val_loss: 0.1162\n",
      "Epoch 604/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1315 - val_loss: 0.1017\n",
      "Epoch 605/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1281 - val_loss: 0.0976\n",
      "Epoch 606/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1297 - val_loss: 0.1005\n",
      "Epoch 607/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1292 - val_loss: 0.1279\n",
      "Epoch 608/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1278 - val_loss: 0.1011\n",
      "Epoch 609/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1210 - val_loss: 0.2001\n",
      "Epoch 610/1000\n",
      "3238/3238 [==============================] - 0s 9us/step - loss: 0.1318 - val_loss: 0.1537\n",
      "Epoch 611/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1234 - val_loss: 0.1138\n",
      "Epoch 612/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1306 - val_loss: 0.1365\n",
      "Epoch 613/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1269 - val_loss: 0.1022\n",
      "Epoch 614/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1285 - val_loss: 0.1377\n",
      "Epoch 615/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1276 - val_loss: 0.1336\n",
      "Epoch 616/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1251 - val_loss: 0.1526\n",
      "Epoch 617/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1297 - val_loss: 0.0934\n",
      "Epoch 618/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1306 - val_loss: 0.1002\n",
      "Epoch 619/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1287 - val_loss: 0.0930\n",
      "Epoch 620/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1265 - val_loss: 0.1083\n",
      "Epoch 621/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1301 - val_loss: 0.1818\n",
      "Epoch 622/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1283 - val_loss: 0.0944\n",
      "Epoch 623/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1270 - val_loss: 0.0934\n",
      "Epoch 624/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1225 - val_loss: 0.1821\n",
      "Epoch 625/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1292 - val_loss: 0.1608\n",
      "Epoch 626/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1261 - val_loss: 0.1146\n",
      "Epoch 627/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1251 - val_loss: 0.1036\n",
      "Epoch 628/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1277 - val_loss: 0.1302\n",
      "Epoch 629/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1282 - val_loss: 0.1047\n",
      "Epoch 630/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1235 - val_loss: 0.1265\n",
      "Epoch 631/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1296 - val_loss: 0.1523\n",
      "Epoch 632/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1329 - val_loss: 0.1303\n",
      "Epoch 633/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1247 - val_loss: 0.1046\n",
      "Epoch 634/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1226 - val_loss: 0.1363\n",
      "Epoch 635/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1308 - val_loss: 0.0933\n",
      "Epoch 636/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1200 - val_loss: 0.1565\n",
      "Epoch 637/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1365 - val_loss: 0.0942\n",
      "Epoch 638/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1241 - val_loss: 0.1197\n",
      "Epoch 639/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1279 - val_loss: 0.1117\n",
      "Epoch 640/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1332 - val_loss: 0.1287\n",
      "Epoch 641/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1287 - val_loss: 0.1360\n",
      "Epoch 642/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1245 - val_loss: 0.1598\n",
      "Epoch 643/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1283 - val_loss: 0.1462\n",
      "Epoch 644/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1288 - val_loss: 0.1019\n",
      "Epoch 645/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1253 - val_loss: 0.1204\n",
      "Epoch 646/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1296 - val_loss: 0.1092\n",
      "Epoch 647/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1228 - val_loss: 0.0996\n",
      "Epoch 648/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1276 - val_loss: 0.1015\n",
      "Epoch 649/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1232 - val_loss: 0.1055\n",
      "Epoch 650/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1278 - val_loss: 0.1059\n",
      "Epoch 651/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1287 - val_loss: 0.1040\n",
      "Epoch 652/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1285 - val_loss: 0.0931\n",
      "Epoch 653/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1230 - val_loss: 0.1116\n",
      "Epoch 654/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1313 - val_loss: 0.1425\n",
      "Epoch 655/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1250 - val_loss: 0.0966\n",
      "Epoch 656/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1258 - val_loss: 0.1103\n",
      "Epoch 657/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1258 - val_loss: 0.1172\n",
      "Epoch 658/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1270 - val_loss: 0.1496\n",
      "Epoch 659/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1276 - val_loss: 0.0997\n",
      "Epoch 660/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1303 - val_loss: 0.0941\n",
      "Epoch 661/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1227 - val_loss: 0.0987\n",
      "Epoch 662/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1280 - val_loss: 0.0993\n",
      "Epoch 663/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1253 - val_loss: 0.0941\n",
      "Epoch 664/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1216 - val_loss: 0.1640\n",
      "Epoch 665/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1296 - val_loss: 0.1464\n",
      "Epoch 666/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1210 - val_loss: 0.0920\n",
      "Epoch 667/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1264 - val_loss: 0.1932\n",
      "Epoch 668/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1247 - val_loss: 0.1456\n",
      "Epoch 669/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1206 - val_loss: 0.1160\n",
      "Epoch 670/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1298 - val_loss: 0.1297\n",
      "Epoch 671/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1215 - val_loss: 0.0970\n",
      "Epoch 672/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1254 - val_loss: 0.1111\n",
      "Epoch 673/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1263 - val_loss: 0.1005\n",
      "Epoch 674/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1270 - val_loss: 0.0925\n",
      "Epoch 675/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1274 - val_loss: 0.1761\n",
      "Epoch 676/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1310 - val_loss: 0.1172\n",
      "Epoch 677/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1224 - val_loss: 0.1299\n",
      "Epoch 678/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1276 - val_loss: 0.1074\n",
      "Epoch 679/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1239 - val_loss: 0.1205\n",
      "Epoch 680/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1242 - val_loss: 0.1456\n",
      "Epoch 681/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1292 - val_loss: 0.1269\n",
      "Epoch 682/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1208 - val_loss: 0.0926\n",
      "Epoch 683/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1212 - val_loss: 0.1569\n",
      "Epoch 684/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1311 - val_loss: 0.1567\n",
      "Epoch 685/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1246 - val_loss: 0.0981\n",
      "Epoch 686/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1188 - val_loss: 0.2542\n",
      "Epoch 687/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1297 - val_loss: 0.1152\n",
      "Epoch 688/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1267 - val_loss: 0.1510\n",
      "Epoch 689/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1256 - val_loss: 0.0998\n",
      "Epoch 690/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1277 - val_loss: 0.1262\n",
      "Epoch 691/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1220 - val_loss: 0.1181\n",
      "Epoch 692/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1198 - val_loss: 0.1037\n",
      "Epoch 693/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1276 - val_loss: 0.1984\n",
      "Epoch 694/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1294 - val_loss: 0.1507\n",
      "Epoch 695/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1198 - val_loss: 0.1554\n",
      "Epoch 696/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1232 - val_loss: 0.0929\n",
      "Epoch 697/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1202 - val_loss: 0.1345\n",
      "Epoch 698/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1311 - val_loss: 0.1031\n",
      "Epoch 699/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1224 - val_loss: 0.1486\n",
      "Epoch 700/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1230 - val_loss: 0.1175\n",
      "Epoch 701/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.1259 - val_loss: 0.1104\n",
      "Epoch 702/1000\n",
      "3238/3238 [==============================] - 0s 16us/step - loss: 0.1298 - val_loss: 0.0981\n",
      "Epoch 703/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.1227 - val_loss: 0.1423\n",
      "Epoch 704/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.1279 - val_loss: 0.1418\n",
      "Epoch 705/1000\n",
      "3238/3238 [==============================] - 0s 22us/step - loss: 0.1234 - val_loss: 0.0910\n",
      "Epoch 706/1000\n",
      "3238/3238 [==============================] - 0s 23us/step - loss: 0.1207 - val_loss: 0.1559\n",
      "Epoch 707/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1238 - val_loss: 0.1114\n",
      "Epoch 708/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1249 - val_loss: 0.1021\n",
      "Epoch 709/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1278 - val_loss: 0.1005\n",
      "Epoch 710/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1194 - val_loss: 0.1271\n",
      "Epoch 711/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1274 - val_loss: 0.1250\n",
      "Epoch 712/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1236 - val_loss: 0.1310\n",
      "Epoch 713/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1279 - val_loss: 0.0940\n",
      "Epoch 714/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1211 - val_loss: 0.0937\n",
      "Epoch 715/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1295 - val_loss: 0.1069\n",
      "Epoch 716/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1217 - val_loss: 0.0983\n",
      "Epoch 717/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1208 - val_loss: 0.1125\n",
      "Epoch 718/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1336 - val_loss: 0.1050\n",
      "Epoch 719/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1197 - val_loss: 0.1142\n",
      "Epoch 720/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1265 - val_loss: 0.0939\n",
      "Epoch 721/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1169 - val_loss: 0.1473\n",
      "Epoch 722/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1219 - val_loss: 0.1491\n",
      "Epoch 723/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1257 - val_loss: 0.1154\n",
      "Epoch 724/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1213 - val_loss: 0.1025\n",
      "Epoch 725/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1193 - val_loss: 0.1293\n",
      "Epoch 726/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1321 - val_loss: 0.1032\n",
      "Epoch 727/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1199 - val_loss: 0.1187\n",
      "Epoch 728/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1258 - val_loss: 0.0955\n",
      "Epoch 729/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1273 - val_loss: 0.1622\n",
      "Epoch 730/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1240 - val_loss: 0.0987\n",
      "Epoch 731/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1194 - val_loss: 0.1168\n",
      "Epoch 732/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1275 - val_loss: 0.1305\n",
      "Epoch 733/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1193 - val_loss: 0.1281\n",
      "Epoch 734/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1223 - val_loss: 0.1106\n",
      "Epoch 735/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1201 - val_loss: 0.1997\n",
      "Epoch 736/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1300 - val_loss: 0.1009\n",
      "Epoch 737/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.1205 - val_loss: 0.1218\n",
      "Epoch 738/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.1204 - val_loss: 0.1175\n",
      "Epoch 739/1000\n",
      "3238/3238 [==============================] - 0s 16us/step - loss: 0.1288 - val_loss: 0.0924\n",
      "Epoch 740/1000\n",
      "3238/3238 [==============================] - 0s 15us/step - loss: 0.1181 - val_loss: 0.1365\n",
      "Epoch 741/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.1237 - val_loss: 0.1009\n",
      "Epoch 742/1000\n",
      "3238/3238 [==============================] - 0s 23us/step - loss: 0.1220 - val_loss: 0.1935\n",
      "Epoch 743/1000\n",
      "3238/3238 [==============================] - 0s 19us/step - loss: 0.1258 - val_loss: 0.1091\n",
      "Epoch 744/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1261 - val_loss: 0.1018\n",
      "Epoch 745/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1201 - val_loss: 0.1666\n",
      "Epoch 746/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1195 - val_loss: 0.1080\n",
      "Epoch 747/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1261 - val_loss: 0.0937\n",
      "Epoch 748/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1241 - val_loss: 0.1672\n",
      "Epoch 749/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1168 - val_loss: 0.1337\n",
      "Epoch 750/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1284 - val_loss: 0.1388\n",
      "Epoch 751/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1236 - val_loss: 0.1015\n",
      "Epoch 752/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1197 - val_loss: 0.0970\n",
      "Epoch 753/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1215 - val_loss: 0.1226\n",
      "Epoch 754/1000\n",
      "3238/3238 [==============================] - 0s 17us/step - loss: 0.1293 - val_loss: 0.1053\n",
      "Epoch 755/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.1235 - val_loss: 0.0968\n",
      "Epoch 756/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1179 - val_loss: 0.1020\n",
      "Epoch 757/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.1232 - val_loss: 0.1086\n",
      "Epoch 758/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1206 - val_loss: 0.1287\n",
      "Epoch 759/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1306 - val_loss: 0.0946\n",
      "Epoch 760/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1228 - val_loss: 0.1683\n",
      "Epoch 761/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1220 - val_loss: 0.1064\n",
      "Epoch 762/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1234 - val_loss: 0.1838\n",
      "Epoch 763/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1251 - val_loss: 0.0983\n",
      "Epoch 764/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1248 - val_loss: 0.1291\n",
      "Epoch 765/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1205 - val_loss: 0.1197\n",
      "Epoch 766/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1217 - val_loss: 0.1010\n",
      "Epoch 767/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1183 - val_loss: 0.1285\n",
      "Epoch 768/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1226 - val_loss: 0.1547\n",
      "Epoch 769/1000\n",
      "3238/3238 [==============================] - ETA: 0s - loss: 0.171 - 0s 13us/step - loss: 0.1217 - val_loss: 0.1527\n",
      "Epoch 770/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1227 - val_loss: 0.0910\n",
      "Epoch 771/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1225 - val_loss: 0.1159\n",
      "Epoch 772/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1178 - val_loss: 0.1295\n",
      "Epoch 773/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1270 - val_loss: 0.0964\n",
      "Epoch 774/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1183 - val_loss: 0.1174\n",
      "Epoch 775/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.1226 - val_loss: 0.1011\n",
      "Epoch 776/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1218 - val_loss: 0.1569\n",
      "Epoch 777/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1218 - val_loss: 0.1340\n",
      "Epoch 778/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1224 - val_loss: 0.0945\n",
      "Epoch 779/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1168 - val_loss: 0.1288\n",
      "Epoch 780/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1302 - val_loss: 0.1560\n",
      "Epoch 781/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1159 - val_loss: 0.1321\n",
      "Epoch 782/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1254 - val_loss: 0.1295\n",
      "Epoch 783/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1196 - val_loss: 0.1807\n",
      "Epoch 784/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1250 - val_loss: 0.1055\n",
      "Epoch 785/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1194 - val_loss: 0.1173\n",
      "Epoch 786/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1237 - val_loss: 0.2177\n",
      "Epoch 787/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1249 - val_loss: 0.1332\n",
      "Epoch 788/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1255 - val_loss: 0.1138\n",
      "Epoch 789/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1222 - val_loss: 0.0934\n",
      "Epoch 790/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1145 - val_loss: 0.1023\n",
      "Epoch 791/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1229 - val_loss: 0.1575\n",
      "Epoch 792/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1219 - val_loss: 0.1217\n",
      "Epoch 793/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1246 - val_loss: 0.0897\n",
      "Epoch 794/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1213 - val_loss: 0.1090\n",
      "Epoch 795/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1223 - val_loss: 0.1408\n",
      "Epoch 796/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1205 - val_loss: 0.1690\n",
      "Epoch 797/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1226 - val_loss: 0.1124\n",
      "Epoch 798/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1222 - val_loss: 0.1019\n",
      "Epoch 799/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1186 - val_loss: 0.0970\n",
      "Epoch 800/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1208 - val_loss: 0.1197\n",
      "Epoch 801/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1198 - val_loss: 0.0967\n",
      "Epoch 802/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1261 - val_loss: 0.0970\n",
      "Epoch 803/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1197 - val_loss: 0.0979\n",
      "Epoch 804/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1180 - val_loss: 0.0963\n",
      "Epoch 805/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1250 - val_loss: 0.1012\n",
      "Epoch 806/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1201 - val_loss: 0.1251\n",
      "Epoch 807/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1314 - val_loss: 0.0979\n",
      "Epoch 808/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1183 - val_loss: 0.0929\n",
      "Epoch 809/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1177 - val_loss: 0.1405\n",
      "Epoch 810/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1276 - val_loss: 0.1302\n",
      "Epoch 811/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1189 - val_loss: 0.1185\n",
      "Epoch 812/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1230 - val_loss: 0.1061\n",
      "Epoch 813/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1190 - val_loss: 0.0934\n",
      "Epoch 814/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1199 - val_loss: 0.1024\n",
      "Epoch 815/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1220 - val_loss: 0.0905\n",
      "Epoch 816/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1184 - val_loss: 0.0947\n",
      "Epoch 817/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1155 - val_loss: 0.1271\n",
      "Epoch 818/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1245 - val_loss: 0.1033\n",
      "Epoch 819/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1175 - val_loss: 0.0975\n",
      "Epoch 820/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1171 - val_loss: 0.1253\n",
      "Epoch 821/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1201 - val_loss: 0.1415\n",
      "Epoch 822/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1204 - val_loss: 0.1011\n",
      "Epoch 823/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1206 - val_loss: 0.1382\n",
      "Epoch 824/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1192 - val_loss: 0.1562\n",
      "Epoch 825/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1210 - val_loss: 0.1397\n",
      "Epoch 826/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1161 - val_loss: 0.1475\n",
      "Epoch 827/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1238 - val_loss: 0.1234\n",
      "Epoch 828/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1223 - val_loss: 0.0941\n",
      "Epoch 829/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1192 - val_loss: 0.0985\n",
      "Epoch 830/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1140 - val_loss: 0.1613\n",
      "Epoch 831/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1228 - val_loss: 0.0946\n",
      "Epoch 832/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1159 - val_loss: 0.0909\n",
      "Epoch 833/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1263 - val_loss: 0.1112\n",
      "Epoch 834/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1180 - val_loss: 0.1095\n",
      "Epoch 835/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1173 - val_loss: 0.1710\n",
      "Epoch 836/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1205 - val_loss: 0.1053\n",
      "Epoch 837/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1179 - val_loss: 0.1387\n",
      "Epoch 838/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1206 - val_loss: 0.0912\n",
      "Epoch 839/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1200 - val_loss: 0.1709\n",
      "Epoch 840/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1190 - val_loss: 0.2115\n",
      "Epoch 841/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1247 - val_loss: 0.1304\n",
      "Epoch 842/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1248 - val_loss: 0.1043\n",
      "Epoch 843/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1214 - val_loss: 0.0902\n",
      "Epoch 844/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1154 - val_loss: 0.0978\n",
      "Epoch 845/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1225 - val_loss: 0.0920\n",
      "Epoch 846/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1171 - val_loss: 0.1564\n",
      "Epoch 847/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1240 - val_loss: 0.1182\n",
      "Epoch 848/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1174 - val_loss: 0.1070\n",
      "Epoch 849/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1200 - val_loss: 0.1001\n",
      "Epoch 850/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1195 - val_loss: 0.1353\n",
      "Epoch 851/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1252 - val_loss: 0.1494\n",
      "Epoch 852/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1183 - val_loss: 0.1198\n",
      "Epoch 853/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1211 - val_loss: 0.0909\n",
      "Epoch 854/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1203 - val_loss: 0.1685\n",
      "Epoch 855/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1193 - val_loss: 0.1278\n",
      "Epoch 856/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1223 - val_loss: 0.1030\n",
      "Epoch 857/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1207 - val_loss: 0.0999\n",
      "Epoch 858/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1236 - val_loss: 0.1170\n",
      "Epoch 859/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1199 - val_loss: 0.1418\n",
      "Epoch 860/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1163 - val_loss: 0.1579\n",
      "Epoch 861/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1262 - val_loss: 0.1036\n",
      "Epoch 862/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1166 - val_loss: 0.0975\n",
      "Epoch 863/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1193 - val_loss: 0.1222\n",
      "Epoch 864/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1168 - val_loss: 0.1232\n",
      "Epoch 865/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1220 - val_loss: 0.1299\n",
      "Epoch 866/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1190 - val_loss: 0.1056\n",
      "Epoch 867/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1145 - val_loss: 0.1210\n",
      "Epoch 868/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1161 - val_loss: 0.1656\n",
      "Epoch 869/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1284 - val_loss: 0.0977\n",
      "Epoch 870/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1183 - val_loss: 0.1177\n",
      "Epoch 871/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1206 - val_loss: 0.0991\n",
      "Epoch 872/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1188 - val_loss: 0.1351\n",
      "Epoch 873/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1180 - val_loss: 0.1122\n",
      "Epoch 874/1000\n",
      "3238/3238 [==============================] - 0s 9us/step - loss: 0.1193 - val_loss: 0.1122\n",
      "Epoch 875/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1164 - val_loss: 0.1051\n",
      "Epoch 876/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1196 - val_loss: 0.1556\n",
      "Epoch 877/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1180 - val_loss: 0.1376\n",
      "Epoch 878/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1199 - val_loss: 0.0997\n",
      "Epoch 879/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1200 - val_loss: 0.1578\n",
      "Epoch 880/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1150 - val_loss: 0.1372\n",
      "Epoch 881/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1226 - val_loss: 0.1127\n",
      "Epoch 882/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1191 - val_loss: 0.0936\n",
      "Epoch 883/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1194 - val_loss: 0.1261\n",
      "Epoch 884/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1182 - val_loss: 0.1302\n",
      "Epoch 885/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1233 - val_loss: 0.1012\n",
      "Epoch 886/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1170 - val_loss: 0.1316\n",
      "Epoch 887/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1187 - val_loss: 0.0946\n",
      "Epoch 888/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1200 - val_loss: 0.1677\n",
      "Epoch 889/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1215 - val_loss: 0.0898\n",
      "Epoch 890/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1177 - val_loss: 0.1311\n",
      "Epoch 891/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1197 - val_loss: 0.1126\n",
      "Epoch 892/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1198 - val_loss: 0.0913\n",
      "Epoch 893/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1195 - val_loss: 0.1335\n",
      "Epoch 894/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1130 - val_loss: 0.1034\n",
      "Epoch 895/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1209 - val_loss: 0.1147\n",
      "Epoch 896/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1175 - val_loss: 0.0914\n",
      "Epoch 897/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1163 - val_loss: 0.1158\n",
      "Epoch 898/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1224 - val_loss: 0.0969\n",
      "Epoch 899/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1193 - val_loss: 0.1072\n",
      "Epoch 900/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1176 - val_loss: 0.1122\n",
      "Epoch 901/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1211 - val_loss: 0.0948\n",
      "Epoch 902/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1189 - val_loss: 0.0931\n",
      "Epoch 903/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1167 - val_loss: 0.1255\n",
      "Epoch 904/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1169 - val_loss: 0.1094\n",
      "Epoch 905/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1252 - val_loss: 0.0980\n",
      "Epoch 906/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1114 - val_loss: 0.0979\n",
      "Epoch 907/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1207 - val_loss: 0.0893\n",
      "Epoch 908/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1207 - val_loss: 0.0893\n",
      "Epoch 909/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1193 - val_loss: 0.0910\n",
      "Epoch 910/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1176 - val_loss: 0.1763\n",
      "Epoch 911/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1223 - val_loss: 0.1347\n",
      "Epoch 912/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1187 - val_loss: 0.1187\n",
      "Epoch 913/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1172 - val_loss: 0.1178\n",
      "Epoch 914/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1134 - val_loss: 0.1936\n",
      "Epoch 915/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1225 - val_loss: 0.1024\n",
      "Epoch 916/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1232 - val_loss: 0.1124\n",
      "Epoch 917/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1129 - val_loss: 0.1144\n",
      "Epoch 918/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1193 - val_loss: 0.1474\n",
      "Epoch 919/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1171 - val_loss: 0.1561\n",
      "Epoch 920/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1194 - val_loss: 0.1003\n",
      "Epoch 921/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1252 - val_loss: 0.1071\n",
      "Epoch 922/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1123 - val_loss: 0.0886\n",
      "Epoch 923/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1191 - val_loss: 0.1076\n",
      "Epoch 924/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1175 - val_loss: 0.1168\n",
      "Epoch 925/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1211 - val_loss: 0.1734\n",
      "Epoch 926/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1185 - val_loss: 0.0948\n",
      "Epoch 927/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1131 - val_loss: 0.1284\n",
      "Epoch 928/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1211 - val_loss: 0.0991\n",
      "Epoch 929/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1137 - val_loss: 0.1320\n",
      "Epoch 930/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1287 - val_loss: 0.1011\n",
      "Epoch 931/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1186 - val_loss: 0.0952\n",
      "Epoch 932/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1260 - val_loss: 0.1236\n",
      "Epoch 933/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1197 - val_loss: 0.0985\n",
      "Epoch 934/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1168 - val_loss: 0.1676\n",
      "Epoch 935/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1157 - val_loss: 0.0995\n",
      "Epoch 936/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1188 - val_loss: 0.0899\n",
      "Epoch 937/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1124 - val_loss: 0.1662\n",
      "Epoch 938/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1224 - val_loss: 0.1352\n",
      "Epoch 939/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1174 - val_loss: 0.0941\n",
      "Epoch 940/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1178 - val_loss: 0.1097\n",
      "Epoch 941/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1166 - val_loss: 0.1161\n",
      "Epoch 942/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1178 - val_loss: 0.1747\n",
      "Epoch 943/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1210 - val_loss: 0.0889\n",
      "Epoch 944/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1171 - val_loss: 0.1109\n",
      "Epoch 945/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1134 - val_loss: 0.1003\n",
      "Epoch 946/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1194 - val_loss: 0.0948\n",
      "Epoch 947/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1139 - val_loss: 0.1271\n",
      "Epoch 948/1000\n",
      "3238/3238 [==============================] - 0s 14us/step - loss: 0.1194 - val_loss: 0.1220\n",
      "Epoch 949/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1178 - val_loss: 0.1198\n",
      "Epoch 950/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1146 - val_loss: 0.2245\n",
      "Epoch 951/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1168 - val_loss: 0.1150\n",
      "Epoch 952/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1209 - val_loss: 0.0954\n",
      "Epoch 953/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1200 - val_loss: 0.1215\n",
      "Epoch 954/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1150 - val_loss: 0.1288\n",
      "Epoch 955/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1204 - val_loss: 0.1064\n",
      "Epoch 956/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1126 - val_loss: 0.1143\n",
      "Epoch 957/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1148 - val_loss: 0.1099\n",
      "Epoch 958/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1240 - val_loss: 0.1359\n",
      "Epoch 959/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1187 - val_loss: 0.0892\n",
      "Epoch 960/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1186 - val_loss: 0.1805\n",
      "Epoch 961/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1163 - val_loss: 0.1036\n",
      "Epoch 962/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1186 - val_loss: 0.1038\n",
      "Epoch 963/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1197 - val_loss: 0.0911\n",
      "Epoch 964/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1165 - val_loss: 0.1071\n",
      "Epoch 965/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1204 - val_loss: 0.1089\n",
      "Epoch 966/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1166 - val_loss: 0.1164\n",
      "Epoch 967/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1144 - val_loss: 0.1455\n",
      "Epoch 968/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1185 - val_loss: 0.0910\n",
      "Epoch 969/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1135 - val_loss: 0.1724\n",
      "Epoch 970/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1211 - val_loss: 0.1159\n",
      "Epoch 971/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1185 - val_loss: 0.0962\n",
      "Epoch 972/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1170 - val_loss: 0.0897\n",
      "Epoch 973/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1192 - val_loss: 0.1308\n",
      "Epoch 974/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1138 - val_loss: 0.1088\n",
      "Epoch 975/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1207 - val_loss: 0.0904\n",
      "Epoch 976/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1181 - val_loss: 0.1018\n",
      "Epoch 977/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1126 - val_loss: 0.0932\n",
      "Epoch 978/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1153 - val_loss: 0.0921\n",
      "Epoch 979/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1142 - val_loss: 0.1268\n",
      "Epoch 980/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1213 - val_loss: 0.1045\n",
      "Epoch 981/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1188 - val_loss: 0.0913\n",
      "Epoch 982/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1187 - val_loss: 0.0935\n",
      "Epoch 983/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1121 - val_loss: 0.1195\n",
      "Epoch 984/1000\n",
      "3238/3238 [==============================] - 0s 13us/step - loss: 0.1145 - val_loss: 0.1264\n",
      "Epoch 985/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1193 - val_loss: 0.0997\n",
      "Epoch 986/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1147 - val_loss: 0.0957\n",
      "Epoch 987/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1151 - val_loss: 0.1819\n",
      "Epoch 988/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1170 - val_loss: 0.0980\n",
      "Epoch 989/1000\n",
      "3238/3238 [==============================] - 0s 12us/step - loss: 0.1148 - val_loss: 0.0985\n",
      "Epoch 990/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1165 - val_loss: 0.0895\n",
      "Epoch 991/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1176 - val_loss: 0.1275\n",
      "Epoch 992/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1122 - val_loss: 0.1029\n",
      "Epoch 993/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1143 - val_loss: 0.0943\n",
      "Epoch 994/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1157 - val_loss: 0.1180\n",
      "Epoch 995/1000\n",
      "3238/3238 [==============================] - 0s 9us/step - loss: 0.1169 - val_loss: 0.1048\n",
      "Epoch 996/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1150 - val_loss: 0.1138\n",
      "Epoch 997/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1128 - val_loss: 0.1207\n",
      "Epoch 998/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1175 - val_loss: 0.1121\n",
      "Epoch 999/1000\n",
      "3238/3238 [==============================] - 0s 10us/step - loss: 0.1140 - val_loss: 0.1038\n",
      "Epoch 1000/1000\n",
      "3238/3238 [==============================] - 0s 11us/step - loss: 0.1146 - val_loss: 0.1053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x18d36e48>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#搭建模型\n",
    "model = Sequential()#定义一个序贯模型\n",
    "model.add(Dense(32, activation='relu', input_shape=(4,)))#将第一个全连接层添加到模型中，该层有32个神经元，激活函数为relu，输入是四维向量\n",
    "model.add(Dense(units=128, activation = 'relu'))#添加第二个全连接层，该层有128个神经元，激活函数为relu\n",
    "model.add(Dense(units=1, activation = 'linear'))#添加第三个全连接层，该层有1个神经元，激活函数为linear\n",
    "model.compile(loss='mse',optimizer='RMSprop')#选择损失函数和优化方法，mse是均方根误差，模型优化器为RMSprop\n",
    "model.fit(train_X, train_y, batch_size=128, epochs=1000, validation_data=(test_X,test_y))\n",
    "#训练集进行训练，测试集进行验证，每次梯度更新样本数为128，运行1000个周期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义画图函数\n",
    "def predict_true_plot(year,gender,region):\n",
    "    predict_x = df.loc[(df['year']==year)&(df['gender']==gender)&(df['region']==region),['year','age','gender','region']]\n",
    "    predict_x.loc[:,'year'] = (predict_x.loc[:,'year']-1995)/(2017-1995)\n",
    "    predict_x.loc[:,'age'] = (predict_x.loc[:,'age']-0)/(100-0)\n",
    "    predict_x.loc[:,'region'] = (predict_x.loc[:,'region']-1)/(4-1)\n",
    "    true_y = df.loc[(df['year']==year)&(df['gender']==gender)&(df['region']==region),'y'].values\n",
    "    predict_y = []\n",
    "    for i in range(0,22):\n",
    "        predict_y.append(model.predict(predict_x.iloc[i,:].values.reshape(1,4))[0,0])\n",
    "    fig,ax = plt.subplots(figsize=(12,8))\n",
    "    ax.plot(true_y,label='实际值')\n",
    "    ax.plot(predict_y,label='拟合值')\n",
    "    ax.legend(fontsize=16)\n",
    "    ax.set_xticks([0,4,8,12,16,20])\n",
    "    ax.set_xticklabels([ 0, 15, 35, 55, 75, 95])\n",
    "    ax.set_yticks([-1,-3,-5,-7,-9])\n",
    "    ax.set_yticklabels([-1,-3,-5,-7,-9])\n",
    "    for ticklabel in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "        ticklabel.set_fontsize(13)\n",
    "    ax.set_xlabel('年龄',fontsize=14)\n",
    "    ax.set_ylabel('死亡率(对数值)',fontsize=14)\n",
    "    gender_dict = {0:'男',1:'女'}\n",
    "    region_dict = {1:'全国',2:'城市',3:'乡镇',4:'农村'}\n",
    "    ax.set_title('%s年%s%s性全年龄组死亡率'% (year,region_dict[region],gender_dict[gender]),fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#第一个参数为年 1995-2017   第二个参数为性别 0，1  第三个参数为地区 1，2，3，4  可任选\n",
    "predict_true_plot(2008,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
